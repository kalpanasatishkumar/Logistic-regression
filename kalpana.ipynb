{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "import scipy.stats as st\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df=pd.read_csv(\"f:/framingham.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>30.30</td>\n",
       "      <td>77.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>33.11</td>\n",
       "      <td>60.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>21.68</td>\n",
       "      <td>79.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>141.5</td>\n",
       "      <td>89.0</td>\n",
       "      <td>26.36</td>\n",
       "      <td>76.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>23.61</td>\n",
       "      <td>93.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0     1   39        4.0              0         0.0     0.0                0   \n",
       "1     0   46        2.0              0         0.0     0.0                0   \n",
       "2     1   48        1.0              1        20.0     0.0                0   \n",
       "3     0   61        3.0              1        30.0     0.0                0   \n",
       "4     0   46        3.0              1        23.0     0.0                0   \n",
       "5     0   43        2.0              0         0.0     0.0                0   \n",
       "6     0   63        1.0              0         0.0     0.0                0   \n",
       "7     0   45        2.0              1        20.0     0.0                0   \n",
       "8     1   52        1.0              0         0.0     0.0                0   \n",
       "9     1   43        1.0              1        30.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
       "2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
       "3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
       "4             0         0    285.0  130.0   84.0  23.10       85.0     85.0   \n",
       "5             1         0    228.0  180.0  110.0  30.30       77.0     99.0   \n",
       "6             0         0    205.0  138.0   71.0  33.11       60.0     85.0   \n",
       "7             0         0    313.0  100.0   71.0  21.68       79.0     78.0   \n",
       "8             1         0    260.0  141.5   89.0  26.36       76.0     79.0   \n",
       "9             1         0    225.0  162.0  107.0  23.61       93.0     88.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  \n",
       "5           0  \n",
       "6           1  \n",
       "7           0  \n",
       "8           0  \n",
       "9           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df.drop(['education'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  age  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0     1   39              0         0.0     0.0                0   \n",
       "1     0   46              0         0.0     0.0                0   \n",
       "2     1   48              1        20.0     0.0                0   \n",
       "3     0   61              1        30.0     0.0                0   \n",
       "4     0   46              1        23.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
       "2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
       "3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
       "4             0         0    285.0  130.0   84.0  23.10       85.0     85.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male                 0\n",
       "age                  0\n",
       "currentSmoker        0\n",
       "cigsPerDay          29\n",
       "BPMeds              53\n",
       "prevalentStroke      0\n",
       "prevalentHyp         0\n",
       "diabetes             0\n",
       "totChol             50\n",
       "sysBP                0\n",
       "diaBP                0\n",
       "BMI                 19\n",
       "heartRate            1\n",
       "glucose            388\n",
       "TenYearCHD           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21b91b615c8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='TenYearCHD',data=heart_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=heart_df.drop(\"TenYearCHD\", axis=1)\n",
    "y=heart_df[\"TenYearCHD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-139fa7af76d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[1;32m-> 1527\u001b[1;33m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[0;32m   1528\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1529\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    753\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 755\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    756\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 578\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                     (type_err,\n\u001b[1;32m---> 60\u001b[1;33m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[0;32m     61\u001b[0m             )\n\u001b[0;32m     62\u001b[0m     \u001b[1;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male               0\n",
       "age                0\n",
       "currentSmoker      0\n",
       "cigsPerDay         0\n",
       "BPMeds             0\n",
       "prevalentStroke    0\n",
       "prevalentHyp       0\n",
       "diabetes           0\n",
       "totChol            0\n",
       "sysBP              0\n",
       "diaBP              0\n",
       "BMI                0\n",
       "heartRate          0\n",
       "glucose            0\n",
       "TenYearCHD         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-139fa7af76d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[1;32m-> 1527\u001b[1;33m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[0;32m   1528\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1529\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    753\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 755\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    756\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 578\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                     (type_err,\n\u001b[1;32m---> 60\u001b[1;33m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[0;32m     61\u001b[0m             )\n\u001b[0;32m     62\u001b[0m     \u001b[1;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   const  male  age  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0    1.0     1   39              0         0.0     0.0                0   \n",
       "1    1.0     0   46              0         0.0     0.0                0   \n",
       "2    1.0     1   48              1        20.0     0.0                0   \n",
       "3    1.0     0   61              1        30.0     0.0                0   \n",
       "4    1.0     0   46              1        23.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
       "2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
       "3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
       "4             0         0    285.0  130.0   84.0  23.10       85.0     85.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.tools import add_constant as add_constant\n",
    "heart_df_constant = add_constant(heart_df)\n",
    "heart_df_constant.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.377036\n",
      "         Iterations 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>TenYearCHD</td>    <th>  No. Observations:  </th>  <td>  3751</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  3736</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    14</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 11 May 2021</td> <th>  Pseudo R-squ.:     </th>  <td>0.1170</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>16:31:29</td>     <th>  Log-Likelihood:    </th> <td> -1414.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -1601.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>2.439e-71</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>           <td>   -8.6532</td> <td>    0.687</td> <td>  -12.589</td> <td> 0.000</td> <td>  -10.000</td> <td>   -7.306</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>male</th>            <td>    0.5742</td> <td>    0.107</td> <td>    5.345</td> <td> 0.000</td> <td>    0.364</td> <td>    0.785</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>             <td>    0.0641</td> <td>    0.007</td> <td>    9.799</td> <td> 0.000</td> <td>    0.051</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>currentSmoker</th>   <td>    0.0739</td> <td>    0.155</td> <td>    0.478</td> <td> 0.633</td> <td>   -0.229</td> <td>    0.377</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cigsPerDay</th>      <td>    0.0184</td> <td>    0.006</td> <td>    3.000</td> <td> 0.003</td> <td>    0.006</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BPMeds</th>          <td>    0.1448</td> <td>    0.232</td> <td>    0.623</td> <td> 0.533</td> <td>   -0.310</td> <td>    0.600</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prevalentStroke</th> <td>    0.7193</td> <td>    0.489</td> <td>    1.471</td> <td> 0.141</td> <td>   -0.239</td> <td>    1.678</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prevalentHyp</th>    <td>    0.2142</td> <td>    0.136</td> <td>    1.571</td> <td> 0.116</td> <td>   -0.053</td> <td>    0.481</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>diabetes</th>        <td>    0.0022</td> <td>    0.312</td> <td>    0.007</td> <td> 0.994</td> <td>   -0.610</td> <td>    0.614</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>totChol</th>         <td>    0.0023</td> <td>    0.001</td> <td>    2.081</td> <td> 0.037</td> <td>    0.000</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sysBP</th>           <td>    0.0154</td> <td>    0.004</td> <td>    4.082</td> <td> 0.000</td> <td>    0.008</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>diaBP</th>           <td>   -0.0040</td> <td>    0.006</td> <td>   -0.623</td> <td> 0.533</td> <td>   -0.016</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BMI</th>             <td>    0.0103</td> <td>    0.013</td> <td>    0.827</td> <td> 0.408</td> <td>   -0.014</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>heartRate</th>       <td>   -0.0023</td> <td>    0.004</td> <td>   -0.549</td> <td> 0.583</td> <td>   -0.010</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>glucose</th>         <td>    0.0076</td> <td>    0.002</td> <td>    3.409</td> <td> 0.001</td> <td>    0.003</td> <td>    0.012</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:             TenYearCHD   No. Observations:                 3751\n",
       "Model:                          Logit   Df Residuals:                     3736\n",
       "Method:                           MLE   Df Model:                           14\n",
       "Date:                Tue, 11 May 2021   Pseudo R-squ.:                  0.1170\n",
       "Time:                        16:31:29   Log-Likelihood:                -1414.3\n",
       "converged:                       True   LL-Null:                       -1601.7\n",
       "Covariance Type:            nonrobust   LLR p-value:                 2.439e-71\n",
       "===================================================================================\n",
       "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "const              -8.6532      0.687    -12.589      0.000     -10.000      -7.306\n",
       "male                0.5742      0.107      5.345      0.000       0.364       0.785\n",
       "age                 0.0641      0.007      9.799      0.000       0.051       0.077\n",
       "currentSmoker       0.0739      0.155      0.478      0.633      -0.229       0.377\n",
       "cigsPerDay          0.0184      0.006      3.000      0.003       0.006       0.030\n",
       "BPMeds              0.1448      0.232      0.623      0.533      -0.310       0.600\n",
       "prevalentStroke     0.7193      0.489      1.471      0.141      -0.239       1.678\n",
       "prevalentHyp        0.2142      0.136      1.571      0.116      -0.053       0.481\n",
       "diabetes            0.0022      0.312      0.007      0.994      -0.610       0.614\n",
       "totChol             0.0023      0.001      2.081      0.037       0.000       0.004\n",
       "sysBP               0.0154      0.004      4.082      0.000       0.008       0.023\n",
       "diaBP              -0.0040      0.006     -0.623      0.533      -0.016       0.009\n",
       "BMI                 0.0103      0.013      0.827      0.408      -0.014       0.035\n",
       "heartRate          -0.0023      0.004     -0.549      0.583      -0.010       0.006\n",
       "glucose             0.0076      0.002      3.409      0.001       0.003       0.012\n",
       "===================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.chisqprob = lambda chisq, df: st.chi2.sf(chisq, df)\n",
    "cols=heart_df_constant.columns[:-1]\n",
    "model=sm.Logit(heart_df.TenYearCHD,heart_df_constant[cols])\n",
    "result=model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "new_features=heart_df[['age','male','cigsPerDay','totChol','sysBP','glucose','TenYearCHD']]\n",
    "x=new_features.iloc[:,:-1]\n",
    "y=new_features.iloc[:,-1]\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.20,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Satish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg=LogisticRegression()\n",
    "logreg.fit(x_train,y_train)\n",
    "y_pred=logreg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21b92a1ffc8>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcIAAAEvCAYAAADWwsEZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAboklEQVR4nO3de5QdZZmo8eftJIRwTYIScpIgAkFuo9xElBEk3BGJDiLgKAFzJocBB4VBB9Tj6KhLQD06zFkiQQYDKqIIhygMigHFCyAXQwRBE1GgJRImQFBCuIT3/LErSSd07967qZ3u6np+WbW66tvfrnp31l799nerisxEkqS66hrsACRJGkwmQklSrZkIJUm1ZiKUJNWaiVCSVGsmQklSrY3s9AXGbH286zNUec889MnBDkEqyQ7RqTMP5Pf9Mw9d3rF4WmWLUJJUax1vEUqS6iGimm0rE6EkqRRR0U5GE6EkqRS2CCVJtWYilCTVWsSgTwAdEBOhJKkktgglSTVm16gkqdZMhJKkWnP5hCSp1mwRSpJqzUQoSao1E6EkqdYC1xFKkmrMFqEkqdZMhJKkWqtqIqxm1JKk2oiIsRFxZUTcHxH3RcQbI2J8RNwQEQuLn+OKuhER50fEoohYEBF79Hd+E6EkqSRdA9ha8u/A9Zm5I/A64D7gLGBeZk4F5hXHAIcDU4ttFnBBK1FLkvSyRXS1vfV/ztgM2A+4GCAzn8vMJ4HpwJyi2hzg7cX+dODSbLgVGBsRE5tdw0QoSSpFJxIhsC3wGHBJRPwqIr4aERsDEzJzMUDxc8ui/iTg4R7v7y7K+mQilCSVIuhqf4uYFRF39NhmrXPakcAewAWZuTvwNGu6QXsP46WyWdzOGpUklWIgs0YzczYwu0mVbqA7M28rjq+kkQgfjYiJmbm46Ppc0qP+lB7vnww80iwGW4SSpFJERNtbfzLzz8DDEfGaouhA4DfAXGBGUTYDuKbYnwucUMwe3QdYtqoLtS+2CCVJpejgOsJ/Ar4RERsADwAn0WjIfTsiZgIPAccUda8DjgAWAcuLuk2ZCCVJpejU8wgzcz6wVy8vHdhL3QRObef8JkJJUimqemcZE6EkqRQmQklSrXWqa7TTTISSpHLYIpQk1Zldo5KkWmtlXeBQZCKUJJXCMUJJUq1VtWu0mlFLklQSW4SSpHI4RihJqrWK9jGaCCVJ5bBFKEmqNROhJKnW7BqVJNVZ2iKUJNVaNfOgiVCSVJKuamZCE6EkqRx2jUqSaq2aedBEKEkqiV2jkqRas2tUklRr1cyDJkJJUknsGpUk1Vo186CJUJJUjqreWaaid4aTJKkctgglSeVwjFCSVGvVzIMmQklSSSo6RmgilCSVw65RSVKtVTMPmgglSSWxa1SSVGsVTYSuI5QklaNrAFsLIuKPEfHriJgfEXcUZeMj4oaIWFj8HFeUR0ScHxGLImJBROzRStiSJL18Ee1vrTsgM3fLzL2K47OAeZk5FZhXHAMcDkwttlnABf2d2EQoSSpHDGAbuOnAnGJ/DvD2HuWXZsOtwNiImNjsRI4RVsTmm23EBefNYucdJpMJJ3/oQg7a/7W87/hpPLb0KQD+9bwr+MFN85n25r/hU2cdxwajRvLc8y/wkc98k5/84t5B/gRS3x54oJvTTz9v9fHDD/+Z0077e048cfogRqV2ZeeWTyTww4hI4MLMnA1MyMzFAJm5OCK2LOpOAh7u8d7uomxxXyc3EVbE5z8xgx/++G7effKXGDVqBBuNGc1B+7+W//jqdXxp9rVr1V36+F945/s+z+JHn2DnHSbzva+fzXZ7nzpIkUv923bbyVxzzfkArFy5kv32O5GDD37jIEeltg1gskxEzKLRhbnK7CLR9bRvZj5SJLsbIuL+ZqfspSybxWAirIBNNxnD3+69I/9wRqOr+/nnV7Ls+eV91r/73j+u3v/N77oZPXoUG2wwkueee6HToUov2y233M2UKROZNGnL/itraBlAg7BIeusmvnXrPFL8XBIRVwN7A49GxMSiNTgRWFJU7wam9Hj7ZOCRZudvOkYYEZtHxLERcUZEnF7sj23+sVS2V2+9Jf/9+FPM/sLJ3HLdZ/nyuf/ARmNGA3DyjEP55Q/O5Suf+1+M3Xzjl7z3HUfszd33/tEkqMq49tqfcuSR+w12GBqIrmh/60dEbBwRm67aBw4B7gHmAjOKajOAa4r9ucAJxezRfYBlq7pQ+wy7ycVPAO4C3gJsBGwMHADcWbym9WTkyBHstuurueiyG3jjEWez/JlnOfOUo7josh+x85s/wBsOO4s/L3mCcz72nrXet9MOk/n02e/m/Wd/dZAil9rz3HPPc+ONt3HYYfsOdigaiM7MGp0A/Cwi7gZ+CVybmdcD5wAHR8RC4ODiGOA64AFgEXARcEp/F2jWNfpRYM/MfHLtzxnjgNuAS/t6Y88+35Hj9mLkJtv3F4ea+NPipfxp8ePcPv/3AFx93W388z9OZ8l/L1td5z8vv5GrLvnw6uNJW43nitln8D9P/zJ/eHDJS84pDUU333wnu+yyHa94xbjBDkUD0YG5Mpn5APC6XsqXAgf2Up5AW5MimnWNBr0PML5IPx83M2dn5l6ZuZdJ8OV79LFldC9eytRtGzOA37Lvrty/sJuttlzTSz390Nfzm982JkptvtlGXPW1D/Pxc7/FLXf8blBilgbi2mtv5q1v3X+ww1DNNGsRfga4KyJ+yJqpqFvTaIJ+qtOBaW1nfPxrXHL++9lg1Ej++NCjzDrzQr7wyRm8dudXkQkPdj/GPxVdoCfPOJTttpnAWae9g7NOewcAb3vPZ1cvs5CGomeeWcEvfjGff/s3ZzhXVkWfPhGNVmQfLza6QQ+lsQYjaMzG+UFmPtHqBcZsfXzTaatSFTzz0CcHOwSpJDt0LFttN/M7bf++//3Fxwx69my6fKJIeN9aT7FIkiosBz2lDUxLt1iLiNnNjiVJ6sTyifWh1QX1F/ZzLEmqu4o+hqmlRJiZdzY7liRpqLTw2tVnIoyI79Hk/myZeVRHIpIkVVNFn2fUrEX4+fUWhSSp+oZb12hm/mR9BiJJqrjh1jW6SkRMBT4L7AxsuKo8M7ftYFySpIrJirYIW+nRvYTGo+5foHHT7UuByzoZlCSpgroGsA0BrYQxJjPn0bgLzYOZ+QlgWmfDkiRVzjBeR7giIrqAhRHxfuBPgE/MlCStbRh3jX6QxvMITwP2BN7LmochSpLUMFxbhJl5e7H7V+CkzoYjSaqsoZHX2tbKrNGb6GVhfWY6TihJWi2HSAuvXa2MEZ7ZY39D4GgaM0glSVpjuCbCXu4r+vOIcLG9JGlYaKVrdHyPwy4aE2a26lhEkqRqquis0Va6Ru+kMUYYNLpE/wDM7GRQkqQKGiIL5NvVSiLcKTNX9CyIiNEdikeSVFUVbRG2kr9/0UvZLWUHIkmquOG2jjAitgImAWMiYnfWrBDZjMYCe0mS1hgiia1dzbpGDwVOBCYDX2BNInwK+Ehnw5IkVU1Vnz7R7HmEc4A5EXF0Zn53PcYkSaqiik6WaSXsPSNi7KqDiBgXEZ/uYEySpCqKaH8bAlpJhIdn5pOrDjLzCeCIzoUkSaqk4TZZpocRETE6M58FiIgxgMsnJElrGyKJrV2tJMKvA/Mi4pLi+CRgTudCkiRVUjXzYEv3Gj0vIhYAB9H4mNcDr+p0YJKkahnOT58A+DPwIvAuGrdYcxapJGltQ2TyS7uaLajfATgOOB5YClwBRGYesJ5ikyRVSUVbhM1mjd4PHAi8LTP/NjP/A1i5fsKSJFVODGBr9dQRIyLiVxHx/eL41RFxW0QsjIgrImKDonx0cbyoeH2b/s7dLBEeTaNL9KaIuCgiDmwvbElSnXR1tb+14QPAfT2OzwW+mJlTgSdY81SkmcATmbk98MWiXvO4+3ohM6/OzGOBHYEfA6cDEyLigog4pK3wJUkaoIiYDLwV+GpxHMA04Mqiyhzg7cX+dNasbLgSOLCo36d+83FmPp2Z38jMI2ncd3Q+cFabn0OSNMx18MYyXwI+TGPSJsAWwJOZ+UJx3E3jIREUPx8GKF5fVtTvU1sN08x8PDMvzMxp7bxPkjT8DSQRRsSsiLijxzZr7XPGkcCSzLyzZ3Evl88WXutVq8snJElqqp8eyF5l5mxgdpMq+wJHRcQRwIY0HgX4JWBsRIwsWn2TgUeK+t3AFKA7IkYCmwOPN4uhovcKlyQNNZ3oGs3MszNzcmZuQ2NJ342Z+ffATcA7i2ozgGuK/bnFMcXrN2Zm0xahiVCSVIr1/PCJfwHOiIhFNMYALy7KLwa2KMrPoIU5LXaNSpJKER1uWmXmj2msYiAzHwD27qXOCuCYds5rIpQklaKid1gzEUqSylHRO6yZCCVJ5bBFKEmqNROhJKnWBrKOcCgwEUqSStHpWaOdYiKUJJWiog1CE6EkqRwmQklSrZkIJUm1VtV1hBUd2pQkqRy2CCVJpbBrVJJUayZCSVKtRUUHCU2EkqRS2CKUJNWaiVCSVGsmQklSrVV0iNBEKEkqhy1CSVKt+fQJSVKt2SKUJNWaD+aVJNVaRfOgiVCSVA4TYR/+tPD4Tl9CkjQEmAglSbXmOkJJUq1VNRFWdNWHJEnlsEUoSSpFV+RghzAgJkJJUimq2jVqIpQklaKqY20mQklSKewalSTVWlW7RqvakpUkDTFdA9j6ExEbRsQvI+LuiLg3Ij5ZlL86Im6LiIURcUVEbFCUjy6OFxWvb9NK3JIkvWxd0f7WgmeBaZn5OmA34LCI2Ac4F/hiZk4FngBmFvVnAk9k5vbAF4t6zeNu/6NKkvRSEdn21p9s+GtxOKrYEpgGXFmUzwHeXuxPL44pXj8w+nksholQklSKDrUIiYgRETEfWALcAPweeDIzXyiqdAOTiv1JwMMAxevLgC2axt3uB5UkqTcDGSOMiFkRcUePbda6583MlZm5GzAZ2BvYqZfLr2pe9pZemzY9nTUqSSrFQJZPZOZsYHaLdZ+MiB8D+wBjI2Jk0eqbDDxSVOsGpgDdETES2Bx4vGncbUctSVIvOtE1GhGvjIixxf4Y4CDgPuAm4J1FtRnANcX+3OKY4vUbM9MWoSSp8zrUspoIzImIEcUlvp2Z34+I3wDfiohPA78CLi7qXwxcFhGLaLQEj+vvAiZCSVIpOrGgPjMXALv3Uv4AjfHCdctXAMe0cw0ToSSpFN5iTZJUa95iTZKkCrJFKEkqRVVbViZCSVIpHCOUJNVaVccITYSSpFKYCCVJteYYoSSp1hwjlCTVml2jkqRas2tUklRrtgglSbUWjhFKkurMFqEkqdYcI5Qk1ZrLJyRJtWbXqCSp1kyEkqRaGzHYAQyQiVCSVIqqjhFWdZKPJEmlsEUoSSqFY4SSpFozEUqSam2EiVCSVGe2CCVJtVbVWaMmQklSKWwRSpJqzQX1kqRas0UoSao1xwglSbXm8glJUq3ZNSpJqrWqJkJvui1JKkVXtL/1JyKmRMRNEXFfRNwbER8oysdHxA0RsbD4Oa4oj4g4PyIWRcSCiNij37hf7geXJAlgRGTbWwteAP45M3cC9gFOjYidgbOAeZk5FZhXHAMcDkwttlnABf1dwEQoSSpF1wC2/mTm4sy8q9j/C3AfMAmYDswpqs0B3l7sTwcuzYZbgbERMbHZNRwjlCSVotNjhBGxDbA7cBswITMXQyNZRsSWRbVJwMM93tZdlC3u67y2CCVJgyYiZkXEHT22WX3U2wT4LvDBzHyq2Sl7KWvaB2uLUJJUioG0CDNzNjC7WZ2IGEUjCX4jM68qih+NiIlFa3AisKQo7wam9Hj7ZOCRpnG3H7YkSS/VickyERHAxcB9mfl/erw0F5hR7M8ArulRfkIxe3QfYNmqLtS+2CKUJJWiQ2OE+wLvBX4dEfOLso8A5wDfjoiZwEPAMcVr1wFHAIuA5cBJ/V3ARChJKkUnEmFm/ozex/0ADuylfgKntnMNE6EkqRRVvbOMiVCSVApvui1JqjUfwyRJqrWqLkMwEVbQ5ZfdzPeu+iUBbDd1Ih/91Lv4wKyLWL58BQBPPP40O+86hXP//cRBjVNqx7RpM9l44zF0dXUxYsQIrrrqi4MdktrkGKHWiyWPLuM73/gZ3/x/H2LDDUfx0TMv40fXz+crc05ZXefs0+fw5gN2GcQopYGZM+czjB+/+WCHoQGq6hhhVVuytbZy5Ys8++zzvPDCSlaseJ5XvHKz1a89/fQK7vzl79l/2q6DGKGkOuqKbHsbCgbUIoyIgzPzhrKDUf+2nLA5756xP+845DOM3nAUe79xB97wptesfv0n8+5hrzdsz8abbDiIUUoDM3Pmx4kIjj32MI499rDBDkdtqlvX6MXA1mUGotY89dRyfnrTvXz3v85m003H8NEzL+P679/JYUfuCcAN/zWfo/5u70GOUmrf5Zefx4QJW7B06ZOcdNL/ZtttJ/P619uzUSVVTYR9do1GxNw+tu8BWzQ7ac+7ic/56g9KD7rObr91IRMnj2fc+E0YOWoE+x+4K7+e/yAAy558mt/c8zBv2m+nQY5Sat+ECY1fK1tsMZaDD34jCxb8bpAjUrs68TzC9aFZi/DNwHuAv65THkDTJkfPu4k//uzcodEJPExstdU47l3wECueeY7RG47ijtsWsdMukwGY98MF7LvfTowePWqQo5Tas3z5Cl588UU22WQjli9fwc9//itOOeW4wQ5LbYqKtgibJcJbgeWZ+ZN1X4iI33YuJDWzy2u35oCD/oYZx36JkSO62GGnSUx/5z4A/Oj6+bz3fQcMcoRS+5YufZJTT/0MACtXruTII/dnv/32HOSo1K6K5kGicX/SzrFFqOFg/OgdBzsEqSQ7dCxf3f7YtW3/vn/9K9866PnTdYSSpFJUtWu0pbHKiJjd7FiSpOE4WaanC/s5liTVXAyRBfLtaikRZuadzY4lSapoz2jfibBYL9hnes/MozoSkSSpkqo6RtisRfj59RaFJKnyKpoH+06Eva0flCSpL1W9xVq/Y4QRMRX4LLAzsPpOzpm5bQfjkiRVTEXzYEuzVy8BLgBeAA4ALgUu62RQkqTqiWh/GwpaSYRjMnMejbvQPJiZnwCmdTYsSVLVxAC2oaCV5RMrIqILWBgR7wf+BGzZ2bAkSVUzVBJbu1ppEX4Q2Ag4DdgTeC8wo5NBSZKqpyva34aCfluEmXl7sftX4KTOhiNJqqohktfa1sqs0ZvoZWF9ZjpOKElabTjfYu3MHvsbAkfTmEEqSdJqw7ZF2Mt9RX8eES62lyStZagsh2hXK12j43scdtGYMLNVxyKSJGk9aqVr9E4aY4RBo0v0D8DMTgYlSaqeofJ8wXa1kgh3yswVPQsiYnSH4pEkVVRVu0ZbSeC/6KXslrIDkSRVW1XvLNNnIoyIrSJiT2BMROweEXsU21toLLCXJGm1TtxrNCL+MyKWRMQ9PcrGR8QNEbGw+DmuKI+IOD8iFkXEgojYo5W4m7UID6XxTMLJwBd6bKcDH2nl5JKk+uhQi/BrwGHrlJ0FzMvMqcC84hjgcGBqsc2i8cCIfjV7HuEcYE5EHJ2Z320tXklSXXXilmmZeXNEbLNO8XTgLcX+HODHwL8U5ZdmZgK3RsTYiJiYmYubXaOVMcI9I2LsqoOIGBcRn27pE0iSamM9jhFOWJXcip+rHgQxCXi4R73uoqypVhLh4Zn55KqDzHwCOKLlcCVJtRCRA9hiVkTc0WOb9XJC6KWs3/u+tbJ8YkREjM7MZwEiYgzg8glJ0loG0sLLzNnA7Dbf9uiqLs+ImAgsKcq7gSk96k0GHunvZK20CL8OzIuImRExE7iBRp+sJEmrrccn1M9lzeMAZwDX9Cg/oZg9ug+wrL/xQWjtXqPnRcQC4CAaCf964FUDiVySNHx1Yl1gRFxOY2LMKyKiG/hX4Bzg20Xj7CHgmKL6dTSG7hYBy2nx0YGtdI0C/Bl4EXgXjVusOYtUkrSWTtxiLTOP7+OlA3upm8Cp7V6jz0QYETsAxwHHA0uBK4DIzAPavYgkafir6i3WmrUI7wd+CrwtMxcBRMTp6yUqSVIFVTMTNmvJHk2jS/SmiLgoIg6kqp9SktRxMYB/Q0GfiTAzr87MY4EdaazaPx2YEBEXRMQh6yk+SVJFRHS1vQ0F/UaRmU9n5jcy80gaazLms+a+bpIkVVpb6TgzH8/MCzNzWqcCkiRVVTUfxNTq8glJkpoaKmN+7TIRSpJKYiKUJNXYUJn80i4ToSSpJLYIJUk15hihJKnWTISSpJpzjFCSVGNR0btumwglSSUxEUqSaswxQklSzTlGKEmqMVuEkqRac7KMJKnmTISSpBoLxwglSfVWzRZhNdO3JEklsUUoSSqFk2UkSTVnIpQk1ZiTZSRJNWeLUJJUY95ZRpJUa06WkSTVnGOEkqQas2tUklRzJkJJUo05RihJqjnHCCVJNVbVMcLIzMGOQS9TRMzKzNmDHYf0cvld1mCoZjtW65o12AFIJfG7rPXORChJqjUToSSp1kyEw4NjKhou/C5rvXOyjCSp1mwRSpJqzUTYIRGxMiLmR8Q9EfGdiNjoZZzrLRHx/WL/qIg4q0ndsRFxygCu8YmIOLOX8oiI8yNiUUQsiIg92j23qm0YfZd3jIhbIuLZ3l5XfZkIO+eZzNwtM3cFngNO7vlikWDa/v/PzLmZeU6TKmOBtn95NHE4MLXYZgEXlHhuVcNw+S4/DpwGfL7Ec2oYMBGuHz8Fto+IbSLivoj4MnAXMCUiDin+Sr2r+Gt7E4CIOCwi7o+InwF/t+pEEXFiRPzfYn9CRFwdEXcX25uAc4Dtir/gP1fU+1BE3F606D7Z41wfjYjfRsSPgNf0Eft04NJsuBUYGxETy/8vUkVU9rucmUsy83bg+c7816iqTIQdFhEjabSqfl0UvYZGYtkdeBr4GHBQZu4B3AGcEREbAhcBbwPeDGzVx+nPB36Sma8D9gDuBc4Cfl/8Bf+hiDiERmtub2A3YM+I2C8i9gSOA3an8cvp9T1iPjkiVv3VPwl4uMc1u4sy1cww+C5LvfJeo50zJiLmF/s/BS4G/gfwYNGyAtgH2Bn4eXHX9g2AW4AdgT9k5kKAiPg6vd9xYxpwAkBmrgSWRcS4deocUmy/Ko43ofHLZFPg6sxcXlxj7qo3ZOZXery/t5sHOtW4XobLd1nqlYmwc57JzN16FhS/IJ7uWQTckJnHr1NvN8pLNgF8NjMvXOcaH2zxGt3AlB7Hk4FHSopN1TBcvstSr+waHVy3AvtGxPYAEbFRROwA3A+8OiK2K+od38f75wH/WLx3RERsBvyFxl/Iq/wAeF+P8ZpJEbElcDPwjogYExGb0ui66s1c4IRiQsQ+wLLMXDzQD6xhqwrfZalXJsJBlJmPAScCl0fEAhq/THbMzBU0uo+uLSYYPNjHKT4AHBARvwbuBHbJzKU0uqfuiYjPZeYPgW8CtxT1rgQ2zcy7gCuA+cB3aXR5AS8ZV7kOeABYRGOsp8xZfBomqvBdjoitIqIbOAP4WER0FwlXNeedZSRJtWaLUJJUayZCSVKtmQglSbVmIpQk1ZqJUJJUayZCSVKtmQglSbVmIpQk1dr/B/7YYzd4o+KHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "conf_matrix=pd.DataFrame(data=cm,columns=['Predicted:0','Predicted:1'],index=['Actual:0','Actual:1'])\n",
    "plt.figure(figsize = (8,5))\n",
    "sns.heatmap(conf_matrix, annot=True,fmt='d',cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
